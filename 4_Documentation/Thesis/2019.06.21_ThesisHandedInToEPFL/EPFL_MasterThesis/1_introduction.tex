\chapter{Introduction}
%\epigraph{\centering \textit{`Averages and relationships and trends and graphs are not always what they seem. There may be more in them than meets the eye, and there may be a good deal less.'}}{--- Darrell Huff,\\ How to Lie with Statistics (1954, p.~8)}
%\epigraph{\centering \textit{`[W]hen it comes to making decisions and statistical inferences, if you can't count you don't count.'}}{--- Stephen Senn, Dicing with Death (2003, p.~xi)}
\epigraph{\centering \textit{`I've been studying statistics for over 40 years \& I still don't understand it. The ease with which non-statisticians master it is staggering.'}}{--- Stephen Senn, Twitter, (\href{https://twitter.com/stephensenn/status/538017638111531009}{November 27, 2014})}

Complaints about statistics (and statisticians) are legion. In the best case, scientists simply find it boring, tedious and obfuscated, but recognise its worth in uncovering scientific facts. In the worst case, they see it as a mere means to an end, the end often being significant findings or findings going into the `desired direction'. Everyone wants evidence, but nobody wants to work for it---or at least collaborate with the ones who are willing to work the stats.\par
This might seem a bit caustic but it exemplifies the reactions that statistics usually evokes. And it it should make clear that many of the problems of scientific research---including the eponymous bias of this thesis---have less to do with statistics and are more deeply rooted in distorting external and internal incentives. Hence, it would be short-sighted to believe that statistical methods will be able to solve problems in research practice without major changes in research culture and specifically the current reward structures within scientific research.\par
Nevertheless, it is crucial to provide a solid statistical basis for the analysis and interpretation of scientific evidence in the face of uncertainty. Therefore, Chapter~\ref{cha:analysing_testing_evidence} provides an overview of basic methods to test hypotheses and compare statistical evidence from different sources, primarily focusing on the idea of variance stabilising transformations and their advantageous properties for testing and comparing scientific findings.\par
Whereas these methods primarily focus on how to calculate comparable evidence measures from a single study, the remainder of the second part of the thesis is concerned with how to combine statistical evidence from multiple studies in the presence of bias. This is crucial to draw the correct inferences about statistical parameters, which is, as William Sealy Gosset puts it in his seminal paper `The probable error of a mean' \citep[p.~1]{student_probable_1908}, the main purpose of scientific experiments: `Any series of experiments is only of value in so far as it enables us to form a judgement as to the statistical constants of the population to which the experiments belong'.\par
It follows then that incomplete and biased publication records heavily undermine the value of scientific research because they prevent a reliable `judgement as to the statistical constants of the population'. Therefore, Chapter~\ref{cha:publication bias} introduces the reader to a variety of sources behind publication bias in general and significance-driven publication bias in particular (Section~\ref{sec:significance_fickle}).\par
In addition, I present a selection of methods to detect (see Section~\ref{sec:detect_publication_bias}) and correct (see Section~\ref{sec:correct_publication_bias}) publication bias.\par
Finally, Chapter~\ref{cha:conclusion_and_limitations} gives the reader a quick overview of additional steps and methods to be used for the detection and correction of publication bias.