print(vst(0.5,0.5,1000))
T_vst_th
T_vst_emp
T_vst_emp > crit_val
T_vst_emp > crit_val_vst
T_vst_emp
sum(T_vst_emp>crit_val_vst)
help(apply)
pows_avg_vst_emp <- apply(1*(T_vst_emp>crit_val_vst),1,mean)
pows_avg_vst_emp
pows_avg_vst_emp <- apply(1*(T_vst_emp>crit_val_vst),2,mean)
pows_avt_vst_emp
pows_avg_vst_emp
T_vst_emp
pows_avg_vst_emp <- T_averager(1*(T_vst_emp>crit_val_vst))
pows_avg_vst_emp
sims <- vector("list",length(n_studies))
i <- 1
for (n_study in n_studies) {
p1_hats <- sapply(p1s,function(x) rbinom(n_sim,n_study,x))/n_study #regular estimator: p_hat <- x/n_study
#p1_hats <- (sapply(p1s,function(x) rbinom(n_sim,n_study,x))+3/8)/(n_study+3/4) #Anscombe estimator (included continuity correction) p_anscombe <- (x+3/8)/(n+3/4)
p1s_th <- matrix(rep(p1s,n_sim),n_sim,length(p1s),byrow=TRUE)
#calculate empirical and theoretical SE
se_hats <- SE_calculator(p1_hats,n_study)
se_th <- SE_calculator(p1s_th, n_study)
#calculate theoretical and empiral evidence based on clt-vst
#question: can I use empirical SE to calculate T_clt_th > how is distribution of this statistic?
T_clt_th <- calc_T_clt(p0s,p1s_th,n_study,se_th,clt)
T_clt_emp <- calc_T_clt(p0s,p1_hats,n_study,se_hats,clt)
T_clt_th_avg <- T_averager(T_clt_th)
T_clt_emp_avg <- T_averager(T_clt_emp)
T_avg_clt <- dat_transform_th_emp(list(T_clt_th_avg,T_clt_emp_avg))
#calculate theoretical and empiral evidence based on binomial vst
T_vst_th <- calc_T_vst(p0s,p1s_th,n_study,vst)
T_vst_emp <- calc_T_vst(p0s,p1_hats,n_study,vst)
T_vst_th_avg <- T_averager(T_vst_th)
T_vst_emp_avg <- T_averager(T_vst_emp)
T_avg_vst <- dat_transform_th_emp(list(T_vst_th_avg,T_vst_emp_avg))
#calculate power
j <- 1
sims_pow <- vector("list",length(alphas))
for (alph in alphas){
#calculate theoretical and empirical power for test using the exact binomial test
crit_vals <- sapply(p0s,function(p0) qbinom(alph,n_study,p0,lower.tail=FALSE))
pows_avg_binom_th <- sapply(1:dim(p1s_th)[2], function(i) apply(sapply(p1s_th[,i], function(p1) 1-pbinom(crit_vals,n_study,p1,lower.tail = TRUE)),1,mean))
#the following is wrong! > reason: it mixes theoretical distribution with indivdual simulations
#pows_avg_binom_emp <- sapply(1:dim(p1s_th)[2], function(i) apply(sapply(p1_hats[,i], function(p1) 1-pbinom(crit_vals,n_study,p1,lower.tail = TRUE)),1,mean))
#UPPER TAIL TRUE, DANN: PBINOM(...)
pows_avg_binom_emp <- sapply(1:dim(p1_hats)[2],
function(i) apply(sapply(p1_hats[,i],
function(p1) test_func(p1*n_study,crit_vals)),1,mean))
pows_avg_binom <- dat_transform_th_emp(list(pows_avg_binom_th,pows_avg_binom_emp))
#calculate theoretical and empirical power for test using the vst
crit_val_vst <- qnorm(alph,mean=0,sd=1,lower.tail = FALSE)
pows_avg_vst_th <- sapply(1:dim(p1s_th)[2],
function(i) sapply(p0s,
function(p0) mean(sapply(p1s_th[,i],
function(p1) 1-pnorm(crit_val_vst,vst(p0,p1,n_study),sd=1)))))
pows_avg_vst_emp <- sapply(1:dim(p1_hats)[2],
function(i) apply(sapply(p1_hats[,i],
function(p1) test_func(vst(p0,p1,n_study),rep(crit_val_vst,length(p0s)))),1,mean))
pows_avg_vst_emp <- T_averager(1*(T_vst_emp>crit_val_vst))
pows_avg_vst <- dat_transform_th_emp(list(pows_avg_vst_th,pows_avg_vst_emp))
#maybe replace sd_th with sd_emp?
#question: in this case, isn't the maximum evidence 1?
#question: what standard deviation do we use? the empirical or the theoretical?
#question: how do we know that approximate standard normality holds for vst?
sims_pow[[j]] <- list(pows_avg_binom,pows_avg_vst)
j <- j+1
}
sims[[i]] <- list(T_avg_clt,T_avg_vst,sims_pow)
print(paste("round",i,"done"))
i <- i+1
}
#question/todo: a lot of 0 values are created empirical SE and low n_study > leads to infinity values for the z-scores based on the empirical variance.
#can be amended by the continuity correction.
# plot values
require("ggplot2") #http://www.sthda.com/english/wiki/ggplot2-histogram-plot-quick-start-guide-r-software-and-data-visualization
require("reshape2") #https://stackoverflow.com/questions/21563864/ggplot2-overlay-density-plots-r
#plot
#for math notation, see here: https://www.r-bloggers.com/math-notation-for-r-plot-titles-expression-and-bquote/
#NamingConvention: Ev_Binom_corr.pdf; EV_DIST_CORR.pdf
pdf("./figs/Ev_Binom_Ans.pdf",onefile=TRUE)
i <- 1
for (sim in sims){
T_clt <- sim[[1]]
T_vst <- sim[[2]]
Ts <- merger(dats =list(T_clt,T_vst),ids=c("T_clt","T_vst"))
T_plot <- ggplot(data=Ts,aes(x=p1,y=Tn/sqrt(n_studies[i]),col=factor(p0),group=interaction(p0,th_emp,id),linetype=id,alpha=th_emp)) +
geom_line() + scale_linetype_manual(values=c("T_clt"=2,"T_vst"=1)) + scale_alpha_manual(values=c("emp"=1,"th"=0.5))+
ylim(-3,3) + xlim(0,1) + ggtitle(bquote("Study size"==.(n_studies[i]))) + labs(x= expression(p[1]), y = "vst (solid), clt (dashed)")
print(T_plot)
#plot the power
pows <- sim[[3]]
j <-1
for (pow in pows){
pow_bin <- pow[[1]]
pow_vst <- pow[[2]]
pows_merged <- merger(dats=list(pow_bin,pow_vst),ids=c("pow_bin","pow_vst"))
pows_merged <- pows_merged[pows_merged$id=="pow_vst" & pows_merged$th_emp=="emp",]
cutoff <- data.frame(x = c(0, 1), y = alphas[j], cutoff = factor(alphas[j]))
p0_cutoff <- data.frame(x = rep(p0s,each=2),y=rep(c(0,1),length(p0s)))
pow_plot <- ggplot(data=pows_merged,aes(x=p1,y=Tn,col=factor(p0),group=interaction(p0,th_emp,id),linetype=id,alpha=th_emp)) +
geom_line() + scale_linetype_manual(values=c("pow_bin"=2,"pow_vst"=1)) +  scale_alpha_manual(values=c("emp"=1,"th"=0.5))+
geom_line(aes(x, y,group=factor(x)),p0_cutoff,inherit.aes=FALSE,alpha=.2) + geom_line(aes(x, y),cutoff,inherit.aes=FALSE,alpha=.2) +
ggtitle(bquote("Study size"==.(n_studies[i])~", alpha"==.(alphas[j]))) + labs(x= expression(p[1]), y = "power")
print(pow_plot)
j <- j+1
}
i <- i+1
}
dev.off()
sims <- vector("list",length(n_studies))
i <- 1
for (n_study in n_studies) {
p1_hats <- sapply(p1s,function(x) rbinom(n_sim,n_study,x))/n_study #regular estimator: p_hat <- x/n_study
#p1_hats <- (sapply(p1s,function(x) rbinom(n_sim,n_study,x))+3/8)/(n_study+3/4) #Anscombe estimator (included continuity correction) p_anscombe <- (x+3/8)/(n+3/4)
p1s_th <- matrix(rep(p1s,n_sim),n_sim,length(p1s),byrow=TRUE)
#calculate empirical and theoretical SE
se_hats <- SE_calculator(p1_hats,n_study)
se_th <- SE_calculator(p1s_th, n_study)
#calculate theoretical and empiral evidence based on clt-vst
#question: can I use empirical SE to calculate T_clt_th > how is distribution of this statistic?
T_clt_th <- calc_T_clt(p0s,p1s_th,n_study,se_th,clt)
T_clt_emp <- calc_T_clt(p0s,p1_hats,n_study,se_hats,clt)
T_clt_th_avg <- T_averager(T_clt_th)
T_clt_emp_avg <- T_averager(T_clt_emp)
T_avg_clt <- dat_transform_th_emp(list(T_clt_th_avg,T_clt_emp_avg))
#calculate theoretical and empiral evidence based on binomial vst
T_vst_th <- calc_T_vst(p0s,p1s_th,n_study,vst)
T_vst_emp <- calc_T_vst(p0s,p1_hats,n_study,vst)
T_vst_th_avg <- T_averager(T_vst_th)
T_vst_emp_avg <- T_averager(T_vst_emp)
T_avg_vst <- dat_transform_th_emp(list(T_vst_th_avg,T_vst_emp_avg))
#calculate power
j <- 1
sims_pow <- vector("list",length(alphas))
for (alph in alphas){
#calculate theoretical and empirical power for test using the exact binomial test
crit_vals <- sapply(p0s,function(p0) qbinom(alph,n_study,p0,lower.tail=FALSE))
pows_avg_binom_th <- sapply(1:dim(p1s_th)[2], function(i) apply(sapply(p1s_th[,i], function(p1) 1-pbinom(crit_vals,n_study,p1,lower.tail = TRUE)),1,mean))
#the following is wrong! > reason: it mixes theoretical distribution with indivdual simulations
#pows_avg_binom_emp <- sapply(1:dim(p1s_th)[2], function(i) apply(sapply(p1_hats[,i], function(p1) 1-pbinom(crit_vals,n_study,p1,lower.tail = TRUE)),1,mean))
#UPPER TAIL TRUE, DANN: PBINOM(...)
pows_avg_binom_emp <- sapply(1:dim(p1_hats)[2],
function(i) apply(sapply(p1_hats[,i],
function(p1) test_func(p1*n_study,crit_vals)),1,mean))
pows_avg_binom <- dat_transform_th_emp(list(pows_avg_binom_th,pows_avg_binom_emp))
#calculate theoretical and empirical power for test using the vst
crit_val_vst <- qnorm(alph,mean=0,sd=1,lower.tail = FALSE)
pows_avg_vst_th <- sapply(1:dim(p1s_th)[2],
function(i) sapply(p0s,
function(p0) mean(sapply(p1s_th[,i],
function(p1) 1-pnorm(crit_val_vst,vst(p0,p1,n_study),sd=1)))))
pows_avg_vst_emp <- sapply(1:dim(p1_hats)[2],
function(i) apply(sapply(p1_hats[,i],
function(p1) test_func(vst(p0,p1,n_study),rep(crit_val_vst,length(p0s)))),1,mean))
pows_avg_vst_emp <- T_averager(1*(T_vst_emp>crit_val_vst))
pows_avg_vst <- dat_transform_th_emp(list(pows_avg_vst_th,pows_avg_vst_emp))
#maybe replace sd_th with sd_emp?
#question: in this case, isn't the maximum evidence 1?
#question: what standard deviation do we use? the empirical or the theoretical?
#question: how do we know that approximate standard normality holds for vst?
sims_pow[[j]] <- list(pows_avg_binom,pows_avg_vst)
j <- j+1
}
sims[[i]] <- list(T_avg_clt,T_avg_vst,sims_pow)
print(paste("round",i,"done"))
i <- i+1
}
n_studies <- c(5,10,20,30,40,50,100,200,500,1000)
n_sim <- 1e2
p0s <- seq(0.1,0.9,by=0.2)
p1s <- seq(0.01,0.99,by=0.01)
alphas <- c(0.05)
# Define vst and helper functions  ----
vst <- function(p0,p1,n){
Tn <- 2*sqrt(n)*(asin(sqrt(p1))-asin(sqrt(p0)))
}
#z-statistic based on CLT
clt <- function(p0,p1,n,SE){
Tn <- (p1-p0)/SE
return(Tn)
}
#question: what changes when we use the theoretical variance instead of the empirical? fit should get better, shouldn't it?
#also: where do peaks come from?
calc_T_vst <- function(p0s,p1s,n_study,func){
Tn <- apply(p1s, 1, function(p1) sapply(p0s, function(p0) func(p0,p1,n_study)))
Tn[is.infinite(Tn)] <- NA
return(Tn)
}
calc_T_clt <- function(p0s,p1s,n_study,SEs,func){
Tn <- sapply(1:dim(p1s)[1], function(p1) sapply(p0s, function(p0) func(p0,p1s[p1,],n_study,SEs[p1,])))
Tn[is.infinite(T)] <- NA
return(Tn)
}
#brings data into the correct form for plottings
dat_transform <- function(T_avg){
dat <- melt(T_avg)
colnames(dat) <- c("p0","p1","Tn")
dat$p1 <- rep(p1s,times=1,each=length(p0s))
dat$p0 <- rep(p0s,times=length(p1s))
return(dat)
}
dat_transform_th_emp <- function(dats,th_emps=c("th", "emp")){
for (i in 1:length(th_emps)){
dat <- dat_transform(dats[[i]])
th_emp <- rep(th_emps[i],dim(dat)[1])
dat$th_emp <- th_emp
dats[[i]] <- dat
}
dats <- do.call("rbind",dats)
return(dats)
}
merger <- function(dats,ids){
for (i in 1:length(ids)){
id <- rep(ids[i],dim(dats[[i]])[1])
dat <- dats[[i]]
dat$id <- id
dats[[i]] <- dat
}
dats <- do.call("rbind",dats)
return(dats)
}
#calcualtes SE of binomial variable X/n
SE_calculator <- function(p,n){
SE <- sqrt(p*(1-p)/n)
return(SE)
}
test_func <- function(val,crit_vals){
return((val>crit_vals)*1)
}
T_averager <- function(Ts){
Ts_avg <- matrix(apply(Ts,1,mean,na.rm=TRUE),length(p0s),length(p1s),byrow=TRUE)
return(Ts_avg)
}
#simulate values
#https://stackoverflow.com/questions/34999019/apply-a-function-to-all-pairwise-combinations-of-list-elements-in-r
sims <- vector("list",length(n_studies))
i <- 1
for (n_study in n_studies) {
p1_hats <- sapply(p1s,function(x) rbinom(n_sim,n_study,x))/n_study #regular estimator: p_hat <- x/n_study
#p1_hats <- (sapply(p1s,function(x) rbinom(n_sim,n_study,x))+3/8)/(n_study+3/4) #Anscombe estimator (included continuity correction) p_anscombe <- (x+3/8)/(n+3/4)
p1s_th <- matrix(rep(p1s,n_sim),n_sim,length(p1s),byrow=TRUE)
#calculate empirical and theoretical SE
se_hats <- SE_calculator(p1_hats,n_study)
se_th <- SE_calculator(p1s_th, n_study)
#calculate theoretical and empiral evidence based on clt-vst
#question: can I use empirical SE to calculate T_clt_th > how is distribution of this statistic?
T_clt_th <- calc_T_clt(p0s,p1s_th,n_study,se_th,clt)
T_clt_emp <- calc_T_clt(p0s,p1_hats,n_study,se_hats,clt)
T_clt_th_avg <- T_averager(T_clt_th)
T_clt_emp_avg <- T_averager(T_clt_emp)
T_avg_clt <- dat_transform_th_emp(list(T_clt_th_avg,T_clt_emp_avg))
#calculate theoretical and empiral evidence based on binomial vst
T_vst_th <- calc_T_vst(p0s,p1s_th,n_study,vst)
T_vst_emp <- calc_T_vst(p0s,p1_hats,n_study,vst)
T_vst_th_avg <- T_averager(T_vst_th)
T_vst_emp_avg <- T_averager(T_vst_emp)
T_avg_vst <- dat_transform_th_emp(list(T_vst_th_avg,T_vst_emp_avg))
#calculate power
j <- 1
sims_pow <- vector("list",length(alphas))
for (alph in alphas){
#calculate theoretical and empirical power for test using the exact binomial test
crit_vals <- sapply(p0s,function(p0) qbinom(alph,n_study,p0,lower.tail=FALSE))
pows_avg_binom_th <- sapply(1:dim(p1s_th)[2], function(i) apply(sapply(p1s_th[,i], function(p1) 1-pbinom(crit_vals,n_study,p1,lower.tail = TRUE)),1,mean))
#the following is wrong! > reason: it mixes theoretical distribution with indivdual simulations
#pows_avg_binom_emp <- sapply(1:dim(p1s_th)[2], function(i) apply(sapply(p1_hats[,i], function(p1) 1-pbinom(crit_vals,n_study,p1,lower.tail = TRUE)),1,mean))
#UPPER TAIL TRUE, DANN: PBINOM(...)
pows_avg_binom_emp <- sapply(1:dim(p1_hats)[2],
function(i) apply(sapply(p1_hats[,i],
function(p1) test_func(p1*n_study,crit_vals)),1,mean))
pows_avg_binom <- dat_transform_th_emp(list(pows_avg_binom_th,pows_avg_binom_emp))
#calculate theoretical and empirical power for test using the vst
crit_val_vst <- qnorm(alph,mean=0,sd=1,lower.tail = FALSE)
pows_avg_vst_th <- sapply(1:dim(p1s_th)[2],
function(i) sapply(p0s,
function(p0) mean(sapply(p1s_th[,i],
function(p1) 1-pnorm(crit_val_vst,vst(p0,p1,n_study),sd=1)))))
pows_avg_vst_emp <- T_averager(1*(T_vst_emp>crit_val_vst))
pows_avg_vst <- dat_transform_th_emp(list(pows_avg_vst_th,pows_avg_vst_emp))
#maybe replace sd_th with sd_emp?
#question: in this case, isn't the maximum evidence 1?
#question: what standard deviation do we use? the empirical or the theoretical?
#question: how do we know that approximate standard normality holds for vst?
sims_pow[[j]] <- list(pows_avg_binom,pows_avg_vst)
j <- j+1
}
sims[[i]] <- list(T_avg_clt,T_avg_vst,sims_pow)
print(paste("round",i,"done"))
i <- i+1
}
pdf("./figs/Ev_Binom_Ans.pdf",onefile=TRUE)
i <- 1
for (sim in sims){
T_clt <- sim[[1]]
T_vst <- sim[[2]]
Ts <- merger(dats =list(T_clt,T_vst),ids=c("T_clt","T_vst"))
T_plot <- ggplot(data=Ts,aes(x=p1,y=Tn/sqrt(n_studies[i]),col=factor(p0),group=interaction(p0,th_emp,id),linetype=id,alpha=th_emp)) +
geom_line() + scale_linetype_manual(values=c("T_clt"=2,"T_vst"=1)) + scale_alpha_manual(values=c("emp"=1,"th"=0.5))+
ylim(-3,3) + xlim(0,1) + ggtitle(bquote("Study size"==.(n_studies[i]))) + labs(x= expression(p[1]), y = "vst (solid), clt (dashed)")
print(T_plot)
#plot the power
pows <- sim[[3]]
j <-1
for (pow in pows){
pow_bin <- pow[[1]]
pow_vst <- pow[[2]]
pows_merged <- merger(dats=list(pow_bin,pow_vst),ids=c("pow_bin","pow_vst"))
pows_merged <- pows_merged[pows_merged$id=="pow_vst" & pows_merged$th_emp=="emp",]
cutoff <- data.frame(x = c(0, 1), y = alphas[j], cutoff = factor(alphas[j]))
p0_cutoff <- data.frame(x = rep(p0s,each=2),y=rep(c(0,1),length(p0s)))
pow_plot <- ggplot(data=pows_merged,aes(x=p1,y=Tn,col=factor(p0),group=interaction(p0,th_emp,id),linetype=id,alpha=th_emp)) +
geom_line() + scale_linetype_manual(values=c("pow_bin"=2,"pow_vst"=1)) +  scale_alpha_manual(values=c("emp"=1,"th"=0.5))+
geom_line(aes(x, y,group=factor(x)),p0_cutoff,inherit.aes=FALSE,alpha=.2) + geom_line(aes(x, y),cutoff,inherit.aes=FALSE,alpha=.2) +
ggtitle(bquote("Study size"==.(n_studies[i])~", alpha"==.(alphas[j]))) + labs(x= expression(p[1]), y = "power")
print(pow_plot)
j <- j+1
}
i <- i+1
}
dev.off()
pdf("./figs/Ev_Binom_Ans.pdf",onefile=TRUE)
i <- 1
for (sim in sims){
T_clt <- sim[[1]]
T_vst <- sim[[2]]
Ts <- merger(dats =list(T_clt,T_vst),ids=c("T_clt","T_vst"))
T_plot <- ggplot(data=Ts,aes(x=p1,y=Tn/sqrt(n_studies[i]),col=factor(p0),group=interaction(p0,th_emp,id),linetype=id,alpha=th_emp)) +
geom_line() + scale_linetype_manual(values=c("T_clt"=2,"T_vst"=1)) + scale_alpha_manual(values=c("emp"=1,"th"=0.5))+
ylim(-3,3) + xlim(0,1) + ggtitle(bquote("Study size"==.(n_studies[i]))) + labs(x= expression(p[1]), y = "vst (solid), clt (dashed)")
print(T_plot)
#plot the power
pows <- sim[[3]]
j <-1
for (pow in pows){
pow_bin <- pow[[1]]
pow_vst <- pow[[2]]
pows_merged <- merger(dats=list(pow_bin,pow_vst),ids=c("pow_bin","pow_vst"))
cutoff <- data.frame(x = c(0, 1), y = alphas[j], cutoff = factor(alphas[j]))
p0_cutoff <- data.frame(x = rep(p0s,each=2),y=rep(c(0,1),length(p0s)))
pow_plot <- ggplot(data=pows_merged,aes(x=p1,y=Tn,col=factor(p0),group=interaction(p0,th_emp,id),linetype=id,alpha=th_emp)) +
geom_line() + scale_linetype_manual(values=c("pow_bin"=2,"pow_vst"=1)) +  scale_alpha_manual(values=c("emp"=1,"th"=0.5))+
geom_line(aes(x, y,group=factor(x)),p0_cutoff,inherit.aes=FALSE,alpha=.2) + geom_line(aes(x, y),cutoff,inherit.aes=FALSE,alpha=.2) +
ggtitle(bquote("Study size"==.(n_studies[i])~", alpha"==.(alphas[j]))) + labs(x= expression(p[1]), y = "power")
print(pow_plot)
j <- j+1
}
i <- i+1
}
dev.off()
n_studies <- c(5,10,20,30,40,50,100,200,500,1000)
n_sim <- 1e5
p0s <- seq(0.1,0.9,by=0.2)
p1s <- seq(0.01,0.99,by=0.01)
alphas <- c(0.05)
# Define vst and helper functions  ----
vst <- function(p0,p1,n){
Tn <- 2*sqrt(n)*(asin(sqrt(p1))-asin(sqrt(p0)))
}
#z-statistic based on CLT
clt <- function(p0,p1,n,SE){
Tn <- (p1-p0)/SE
return(Tn)
}
#question: what changes when we use the theoretical variance instead of the empirical? fit should get better, shouldn't it?
#also: where do peaks come from?
calc_T_vst <- function(p0s,p1s,n_study,func){
Tn <- apply(p1s, 1, function(p1) sapply(p0s, function(p0) func(p0,p1,n_study)))
Tn[is.infinite(Tn)] <- NA
return(Tn)
}
calc_T_clt <- function(p0s,p1s,n_study,SEs,func){
Tn <- sapply(1:dim(p1s)[1], function(p1) sapply(p0s, function(p0) func(p0,p1s[p1,],n_study,SEs[p1,])))
Tn[is.infinite(T)] <- NA
return(Tn)
}
#brings data into the correct form for plottings
dat_transform <- function(T_avg){
dat <- melt(T_avg)
colnames(dat) <- c("p0","p1","Tn")
dat$p1 <- rep(p1s,times=1,each=length(p0s))
dat$p0 <- rep(p0s,times=length(p1s))
return(dat)
}
dat_transform_th_emp <- function(dats,th_emps=c("th", "emp")){
for (i in 1:length(th_emps)){
dat <- dat_transform(dats[[i]])
th_emp <- rep(th_emps[i],dim(dat)[1])
dat$th_emp <- th_emp
dats[[i]] <- dat
}
dats <- do.call("rbind",dats)
return(dats)
}
merger <- function(dats,ids){
for (i in 1:length(ids)){
id <- rep(ids[i],dim(dats[[i]])[1])
dat <- dats[[i]]
dat$id <- id
dats[[i]] <- dat
}
dats <- do.call("rbind",dats)
return(dats)
}
#calcualtes SE of binomial variable X/n
SE_calculator <- function(p,n){
SE <- sqrt(p*(1-p)/n)
return(SE)
}
test_func <- function(val,crit_vals){
return((val>crit_vals)*1)
}
T_averager <- function(Ts){
Ts_avg <- matrix(apply(Ts,1,mean,na.rm=TRUE),length(p0s),length(p1s),byrow=TRUE)
return(Ts_avg)
}
#simulate values
#https://stackoverflow.com/questions/34999019/apply-a-function-to-all-pairwise-combinations-of-list-elements-in-r
sims <- vector("list",length(n_studies))
i <- 1
for (n_study in n_studies) {
p1_hats <- sapply(p1s,function(x) rbinom(n_sim,n_study,x))/n_study #regular estimator: p_hat <- x/n_study
#p1_hats <- (sapply(p1s,function(x) rbinom(n_sim,n_study,x))+3/8)/(n_study+3/4) #Anscombe estimator (included continuity correction) p_anscombe <- (x+3/8)/(n+3/4)
p1s_th <- matrix(rep(p1s,n_sim),n_sim,length(p1s),byrow=TRUE)
#calculate empirical and theoretical SE
se_hats <- SE_calculator(p1_hats,n_study)
se_th <- SE_calculator(p1s_th, n_study)
#calculate theoretical and empiral evidence based on clt-vst
#question: can I use empirical SE to calculate T_clt_th > how is distribution of this statistic?
T_clt_th <- calc_T_clt(p0s,p1s_th,n_study,se_th,clt)
T_clt_emp <- calc_T_clt(p0s,p1_hats,n_study,se_hats,clt)
T_clt_th_avg <- T_averager(T_clt_th)
T_clt_emp_avg <- T_averager(T_clt_emp)
T_avg_clt <- dat_transform_th_emp(list(T_clt_th_avg,T_clt_emp_avg))
#calculate theoretical and empiral evidence based on binomial vst
T_vst_th <- calc_T_vst(p0s,p1s_th,n_study,vst)
T_vst_emp <- calc_T_vst(p0s,p1_hats,n_study,vst)
T_vst_th_avg <- T_averager(T_vst_th)
T_vst_emp_avg <- T_averager(T_vst_emp)
T_avg_vst <- dat_transform_th_emp(list(T_vst_th_avg,T_vst_emp_avg))
#calculate power
j <- 1
sims_pow <- vector("list",length(alphas))
for (alph in alphas){
#calculate theoretical and empirical power for test using the exact binomial test
crit_vals <- sapply(p0s,function(p0) qbinom(alph,n_study,p0,lower.tail=FALSE))
pows_avg_binom_th <- sapply(1:dim(p1s_th)[2], function(i) apply(sapply(p1s_th[,i], function(p1) 1-pbinom(crit_vals,n_study,p1,lower.tail = TRUE)),1,mean))
#the following is wrong! > reason: it mixes theoretical distribution with indivdual simulations
#pows_avg_binom_emp <- sapply(1:dim(p1s_th)[2], function(i) apply(sapply(p1_hats[,i], function(p1) 1-pbinom(crit_vals,n_study,p1,lower.tail = TRUE)),1,mean))
#UPPER TAIL TRUE, DANN: PBINOM(...)
pows_avg_binom_emp <- sapply(1:dim(p1_hats)[2],
function(i) apply(sapply(p1_hats[,i],
function(p1) test_func(p1*n_study,crit_vals)),1,mean))
pows_avg_binom <- dat_transform_th_emp(list(pows_avg_binom_th,pows_avg_binom_emp))
#calculate theoretical and empirical power for test using the vst
crit_val_vst <- qnorm(alph,mean=0,sd=1,lower.tail = FALSE)
pows_avg_vst_th <- sapply(1:dim(p1s_th)[2],
function(i) sapply(p0s,
function(p0) mean(sapply(p1s_th[,i],
function(p1) 1-pnorm(crit_val_vst,vst(p0,p1,n_study),sd=1)))))
pows_avg_vst_emp <- T_averager(1*(T_vst_emp>crit_val_vst))
pows_avg_vst <- dat_transform_th_emp(list(pows_avg_vst_th,pows_avg_vst_emp))
#maybe replace sd_th with sd_emp?
#question: in this case, isn't the maximum evidence 1?
#question: what standard deviation do we use? the empirical or the theoretical?
#question: how do we know that approximate standard normality holds for vst?
sims_pow[[j]] <- list(pows_avg_binom,pows_avg_vst)
j <- j+1
}
sims[[i]] <- list(T_avg_clt,T_avg_vst,sims_pow)
print(paste("round",i,"done"))
i <- i+1
}
#question/todo: a lot of 0 values are created empirical SE and low n_study > leads to infinity values for the z-scores based on the empirical variance.
#can be amended by the continuity correction.
# plot values
require("ggplot2") #http://www.sthda.com/english/wiki/ggplot2-histogram-plot-quick-start-guide-r-software-and-data-visualization
require("reshape2") #https://stackoverflow.com/questions/21563864/ggplot2-overlay-density-plots-r
#plot
#for math notation, see here: https://www.r-bloggers.com/math-notation-for-r-plot-titles-expression-and-bquote/
#NamingConvention: Ev_Binom_corr.pdf; EV_DIST_CORR.pdf
pdf("./figs/Ev_Binom_Ans.pdf",onefile=TRUE)
i <- 1
for (sim in sims){
T_clt <- sim[[1]]
T_vst <- sim[[2]]
Ts <- merger(dats =list(T_clt,T_vst),ids=c("T_clt","T_vst"))
T_plot <- ggplot(data=Ts,aes(x=p1,y=Tn/sqrt(n_studies[i]),col=factor(p0),group=interaction(p0,th_emp,id),linetype=id,alpha=th_emp)) +
geom_line() + scale_linetype_manual(values=c("T_clt"=2,"T_vst"=1)) + scale_alpha_manual(values=c("emp"=1,"th"=0.5))+
ylim(-3,3) + xlim(0,1) + ggtitle(bquote("Study size"==.(n_studies[i]))) + labs(x= expression(p[1]), y = "vst (solid), clt (dashed)")
print(T_plot)
#plot the power
pows <- sim[[3]]
j <-1
for (pow in pows){
pow_bin <- pow[[1]]
pow_vst <- pow[[2]]
pows_merged <- merger(dats=list(pow_bin,pow_vst),ids=c("pow_bin","pow_vst"))
cutoff <- data.frame(x = c(0, 1), y = alphas[j], cutoff = factor(alphas[j]))
p0_cutoff <- data.frame(x = rep(p0s,each=2),y=rep(c(0,1),length(p0s)))
pow_plot <- ggplot(data=pows_merged,aes(x=p1,y=Tn,col=factor(p0),group=interaction(p0,th_emp,id),linetype=id,alpha=th_emp)) +
geom_line() + scale_linetype_manual(values=c("pow_bin"=2,"pow_vst"=1)) +  scale_alpha_manual(values=c("emp"=1,"th"=0.5))+
geom_line(aes(x, y,group=factor(x)),p0_cutoff,inherit.aes=FALSE,alpha=.2) + geom_line(aes(x, y),cutoff,inherit.aes=FALSE,alpha=.2) +
ggtitle(bquote("Study size"==.(n_studies[i])~", alpha"==.(alphas[j]))) + labs(x= expression(p[1]), y = "power")
print(pow_plot)
j <- j+1
}
i <- i+1
}
dev.off()
