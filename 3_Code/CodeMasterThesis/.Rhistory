#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
lik <- calculate_pub_prob(dat, p)  * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
lik <- calculate_pub_prob(dat, p) * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
clt_mix
select_studies
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, sample_seed, T_id = "clt")
clt
dat
dat <- evidence_df[mu1 == mu1_select & n_study %between% rng, ]
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, sample_seed, T_id = "clt")
clt
clt_mix <- rbind(clt_sig, select_studies(clt[H1 == 0, ], sel_prob, n_studies_selected, n_select = NULL, sample_seed, T_id = "clt"))
## Situtation 2B:
## only keep studies which turned out to be significant
clt_sig <- clt[H1 == 1, ]
clt_mix <- rbind(clt_sig, select_studies(clt[H1 == 0, ], sel_prob, n_studies_selected, n_select = NULL, sample_seed, T_id = "clt"))
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
clt_mix
hist(clt_mix$n_study)
hist(clt$n_study)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, sample_seed, T_id = "clt")
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, sample_seed, T_id = "clt")
help(randint)
help(rand)
help(rint)
help(runif)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*10, T_id = "clt")
)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*10), T_id = "clt")
clt
hist(clt$n_study)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*10), T_id = "clt")
hist(clt$n_study)
runif(1)
runif(1)*100
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*100), T_id = "clt")
runif(1)*100
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*100), T_id = "clt")
runif(1)*100
hist(clt$n_study)
runif(1)*100
hist(clt$n_study)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*100), T_id = "clt")
hist(clt$n_study)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*100), T_id = "clt")
hist(clt$n_study)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*100), T_id = "clt")
hist(clt$n_study)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*100), T_id = "clt")
hist(clt$n_study)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*100), T_id = "clt")
hist(clt$n_study)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*100), T_id = "clt")
hist(clt$n_study)
hist(dat$n_study)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, sample_seed, T_id = "clt")
## Situtation 2B:
## only keep studies which turned out to be significant
clt_sig <- clt[H1 == 1, ]
clt_mix <- rbind(clt_sig, select_studies(clt[H1 == 0, ], sel_prob, n_studies_selected, n_select = NULL, sample_seed, T_id = "clt"))
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
clt_mix
help(do.call)
x_10 <- rnorm(0,1/sqrt(10))
x_10 <- rnorm(1000,0,1/sqrt(10))
x_20 <- rnorm(1000,0,1/sqrt(10))
x_mean <- sapply(seq(1,100), function(i) rnorm(1000,0,1/sqrt(i)))
x_mean
plot(density(x_mean[, 1]))
plot(density(x_mean[, 2]))
plot(density(x_mean[, 3]))
plot(density(x_mean[, 1]))
points(density(x_mean[, 40]),col="red")
significant <- x_mean > 1.64)
significant <- (x_mean > 1.64)
significant
help(sum)
probs <- colSums(significant,dims=1)
probs
x_mean
# check beahviour of significance given increasing n
x_mean <- sapply(seq(1,100), function(i) rnorm(1000,0,1/sqrt(i))*sqrt(i)/1)
x_mean
plot(x_mean[,1])
plot(densiytx_mean[,1])
plot(density(tx_mean[,1]))
plot(density(x_mean[,1]))
plot(density(x_mean[,100]))
plot(density(x_mean[,1]))
points(density(x_mean[,1]))
points(density(x_mean[,100]))
points(density(x_mean[,50]))
points(density(x_mean[,30]))
# check beahviour of significance given increasing n
x_mean <- sapply(seq(1,100), function(i) rnorm(1e4,0,1/sqrt(i))*sqrt(i)/1)
plot(density(x_mean[,1]))
points(density(x_mean[,30]))
points(density(x_mean[,100]))
# check beahviour of significance given increasing n
x_mean <- sapply(seq(1,100), function(i) rnorm(1e4,1*sqrt(i),1/sqrt(i))*sqrt(i)/1)
plot(density(x_mean[,1]))
points(density(x_mean[,100]))
points(density(x_mean[,300]))
points(density(x_mean[,30]))
points(density(x_mean[,10]))
points(density(x_mean[,4]))
points(density(x_mean[,2]))
points(density(x_mean[,3]))
# check beahviour of significance given increasing n
x_mean <- sapply(seq(1,100), function(i) rnorm(1e4,1,1/sqrt(i))*sqrt(i)/1)
plot(density(x_mean[,1]))
linespoints(density(x_mean[,3]))
lines(density(x_mean[,3]))
lines(density(x_mean[,4]))
significant <- x_mean > 1.64
prob_sig <- colSums(significant)/dim(significant)[1]
prob_sig
# check beahviour of significance given increasing n
x_mean <- sapply(seq(1,100), function(i) rnorm(1e4,0.2,1/sqrt(i))*sqrt(i)/1)
significant <- x_mean > 1.64
prob_sig <- colSums(significant)/dim(significant)[1]
Z <- sapp
plot(seq(1,100),prob_sig)
plot(seq(1,100),prob_sig,type="l")
# check beahviour of significance given increasing n
x_mean <- sapply(seq(1,100), function(i) rnorm(1e5,0.2,1/sqrt(i))*sqrt(i)/1)
significant <- x_mean > 1.64
prob_sig <- colSums(significant)/dim(significant)[1]
plot(seq(1,100),prob_sig,type="l")
prob_sig
prob_sig
prob(1,2)
pnorm(1,2,1)
pnorm(1,3,1)
pnorm(1,4,1)
pnorm(1,4,1)
pnorm(1,4,1, lower.tail= False)
pnorm(1,4,1, lower.tail= F)
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
#expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
clt_mix
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
clt_mix
hist(clt_mix$n_study)
clt_mix$n_study
n_studies
n_studies <- clt_mix$n_study
z <- clt_mix$Tn
alph
p
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob
# expected publication probability
# theta = mu/sgm
exp_pub_prob <- function(theta, alph, p, n_study) {
quant <- qnorm(alph, 0, 1, lower.tail = FALSE)
expect <- p * pnorm(quant, theta * sqrt(n_study), 1) + 1 * pnorm(quant, theta * sqrt(n_study), 1, lower.tail = FALSE)
return(expect)
}
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob
n_studies
theta
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(-2, alph, p, n_study))
expected_pub_prob
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(2, alph, p, n_study))
expected_pub_prob
calculate_pub_prob(clt_mix, 0.1)
calculate_pub_prob(clt_mix, 0.1)/expected_pub_prob
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(0.4, alph, p, n_study))
calculate_pub_prob(clt_mix, 0.1)/expected_pub_prob
clt_mix$Tn
clt_mix$mu_hat
clt_mix$mu1_hat
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(0.1, alph, p, n_study))
calculate_pub_prob(clt_mix, 0.1)/expected_pub_prob
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
calculate_pub_prob(clt_mix, 0.1)/expected_pub_prob*likelihood
plot(clt_mix$Tn,  calculate_pub_prob(clt_mix, 0.1)/expected_pub_prob*likelihood)
plot(density(clt_mix$Tn))
lines(clt_mix$Tn,  calculate_pub_prob(clt_mix, 0.1)/expected_pub_prob*likelihood)
points(clt_mix$Tn,  calculate_pub_prob(clt_mix, 0.1)/expected_pub_prob*likelihood)
plot(density(clt_mix$Tn))
points(clt_mix$Tn,  calculate_pub_prob(clt_mix, 0.1)/expected_pub_prob*likelihood)
theta
T_corr
plot(density(clt))
plot(density(clt$Tn))
mean(clt$Tn)
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
#expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#print(exp_pub_prob(theta, alph, p))
lik <- likelihood
return(lik)
}
# check beahviour of significance given increasing n
x_mean <- sapply(seq(1,100), function(i) rnorm(1e5,0.2,1/sqrt(i))*sqrt(i)/1)
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
mean(clt_mix$Tn)
T_corr
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr
mean(clt$Tn)
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr
# expected publication probability
# theta = mu/sgm
exp_pub_prob <- function(theta, alph, p, n_study) {
quant <- qnorm(alph, 0, 1, lower.tail = FALSE)
expect <- p * pnorm(quant / sqrt(n_study), theta, 1 / sqrt(n_study)) +
1 * pnorm(quant / sqrt(n_study), theta, 1 / sqrt(n_study), lower.tail = FALSE)
return(expect)
}
# expected publication probability
# theta = mu/sgm
exp_pub_prob <- function(theta, alph, p, n_study) {
quant <- qnorm(alph, 0, 1, lower.tail = FALSE)
expect <- p * pnorm(quant / sqrt(n_study), theta, 1 / sqrt(n_study)) +
1 * pnorm(quant / sqrt(n_study), theta, 1 / sqrt(n_study), lower.tail = FALSE)
return(expect)
}
# likelihood function
likeli <- function(z, theta, n_study) {
lik <- dnorm(z / sqrt(n_study), mean = theta, 1 / sqrt(n_study)) # same as: dnorm(z-theta,0,1)
return(lik)
}
# expected publication probability
# theta = mu/sgm
exp_pub_prob <- function(theta, alph, p, n_study) {
quant <- qnorm(alph, 0, 1, lower.tail = FALSE)
expect <- p * pnorm(quant / sqrt(n_study), theta, 1 / sqrt(n_study)) +
1 * pnorm(quant / sqrt(n_study), theta, 1 / sqrt(n_study), lower.tail = FALSE)
return(expect)
}
# likelihood function
likeli <- function(z, theta, n_study) {
lik <- dnorm(z / sqrt(n_study), mean = theta, 1 / sqrt(n_study)) # same as: dnorm(z-theta,0,1)
return(lik)
}
# likelihood function
likeli <- function(z, theta, n_study) {
lik <- dnorm(z / sqrt(n_study), mean = theta, 1 / sqrt(n_study)) # same as: dnorm(z-theta,0,1)
return(lik)
}
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
#expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#print(exp_pub_prob(theta, alph, p))
#lik <- likelihood
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr
aggregate_mean(clt_mix)
pnorm(1-2*3,0,1)
pnorm(1-1*3,0,1)
pnorm(1/3-1,0,1/3)
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
mu_corr <- T_corr*clt_mix$sgm_th[1]
# transform Z scores into estimates of mu
z_to_mu <- function(z, n, sgm_X) {
mu_hat <- z * sgm_X / sqrt(n)
return(mu_hat)
}
mu_corr
T_corr
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
mu_corr <- T_corr*clt_mix$sgm_th[1]
mu_corr
trunc_mle <- function(dat, thetas, p) {
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p)))
plot(thetas, likelihoods, type = "l")
T_corr_mle <- thetas[which(max(likelihoods) == likelihoods)]
mu_corr_mle <- T_corr_mle * dat$sgm_th[1]
return(mu_corr_mle)
}
trunc_mle <- function(dat, thetas, p) {
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p)))
plot(thetas, likelihoods, type = "l")
T_corr_mle <- thetas[which(max(likelihoods) == likelihoods)]
mu_corr_mle <- T_corr_mle * dat$sgm_th[1]
return(mu_corr_mle)
}
mu_corr <- trunc_mle(clt_mix, thetas, p = 0.1)
mu_corr
thetas <- seq(-2, 2, by = 0.001) # theta = mu / sgm_th
mu_corr <- trunc_mle(clt_mix, thetas, p = 0.1)
mu_corr
ps <- seq(0, 1, by = 0.01)
mu_corr <- sapply(ps, function(p) trunc_mle(clt_mix, thetas, p))
trunc_mle <- function(dat, thetas, p) {
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p)))
#plot(thetas, likelihoods, type = "l")
T_corr_mle <- thetas[which(max(likelihoods) == likelihoods)]
mu_corr_mle <- T_corr_mle * dat$sgm_th[1]
return(mu_corr_mle)
}
thetas <- seq(-2, 2, by = 0.001) # theta = mu / sgm_th
mu_corr <- trunc_mle(clt_mix, thetas, p = 0.1)
mu_corr
ps <- seq(0, 1, by = 0.01)
mu_corr <- sapply(ps, function(p) trunc_mle(clt_mix, thetas, p))
# for optimisations
require("NMOF")
help(gridSearch)
