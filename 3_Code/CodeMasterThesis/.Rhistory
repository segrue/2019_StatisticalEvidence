#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) * expected_pub_prob * likelihood
lik
pnorm(1.64,2,1)
pnorm(1.64-2,0,1)
sapply(thetas, function(theta) sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study)))
exp_probs <- sapply(thetas, function(theta) sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study)))
dim(exp_probs)
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 0.1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 0.1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 0.5)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
aggregate_mean(clt)
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = 0.1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
# expected publication probability
# theta = mu/sgm
exp_pub_prob <- function(theta, alph, p, n_study) {
quant <- qnorm(alph, 0, 1, lower.tail = FALSE)
expect <- p * pnorm(quant, theta, 1) + 1 * pnorm(quant, theta, 1, lower.tail = FALSE)
return(expect)
}
exp_pub_prob2 <- function(theta, alph, p) {
quant <- qnorm(alph, 0, 1, lower.tail = FALSE)
expect <- p * pnorm(quant, theta, 1) + 1 * pnorm(quant, theta, 1, lower.tail = FALSE)
return(expect)
}
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = 0.1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
#expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = 0.1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
#expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = 0.1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
calculate_pub_prob(clt_mix, 0.1)
calculate_pub_prob(clt_mix, 1)
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p)  * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p)  * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
lik <- calculate_pub_prob(dat, p)  * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
lik <- calculate_pub_prob(dat, p) * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
clt_mix
select_studies
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, sample_seed, T_id = "clt")
clt
dat
dat <- evidence_df[mu1 == mu1_select & n_study %between% rng, ]
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, sample_seed, T_id = "clt")
clt
clt_mix <- rbind(clt_sig, select_studies(clt[H1 == 0, ], sel_prob, n_studies_selected, n_select = NULL, sample_seed, T_id = "clt"))
## Situtation 2B:
## only keep studies which turned out to be significant
clt_sig <- clt[H1 == 1, ]
clt_mix <- rbind(clt_sig, select_studies(clt[H1 == 0, ], sel_prob, n_studies_selected, n_select = NULL, sample_seed, T_id = "clt"))
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
clt_mix
hist(clt_mix$n_study)
hist(clt$n_study)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, sample_seed, T_id = "clt")
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, sample_seed, T_id = "clt")
help(randint)
help(rand)
help(rint)
help(runif)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*10, T_id = "clt")
)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*10), T_id = "clt")
clt
hist(clt$n_study)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*10), T_id = "clt")
hist(clt$n_study)
runif(1)
runif(1)*100
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*100), T_id = "clt")
runif(1)*100
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*100), T_id = "clt")
runif(1)*100
hist(clt$n_study)
runif(1)*100
hist(clt$n_study)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*100), T_id = "clt")
hist(clt$n_study)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*100), T_id = "clt")
hist(clt$n_study)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*100), T_id = "clt")
hist(clt$n_study)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*100), T_id = "clt")
hist(clt$n_study)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*100), T_id = "clt")
hist(clt$n_study)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, round(runif(1)*100), T_id = "clt")
hist(clt$n_study)
hist(dat$n_study)
clt <- select_studies(dat, 0.2, n_studies_selected, n_select = NULL, sample_seed, T_id = "clt")
## Situtation 2B:
## only keep studies which turned out to be significant
clt_sig <- clt[H1 == 1, ]
clt_mix <- rbind(clt_sig, select_studies(clt[H1 == 0, ], sel_prob, n_studies_selected, n_select = NULL, sample_seed, T_id = "clt"))
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
