expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
#expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#print(exp_pub_prob(theta, alph, p))
return(lik)
}
clt_mix
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
clt_mix
hist(clt_mix$n_study)
clt_mix$n_study
n_studies
n_studies <- clt_mix$n_study
z <- clt_mix$Tn
alph
p
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob
# expected publication probability
# theta = mu/sgm
exp_pub_prob <- function(theta, alph, p, n_study) {
quant <- qnorm(alph, 0, 1, lower.tail = FALSE)
expect <- p * pnorm(quant, theta * sqrt(n_study), 1) + 1 * pnorm(quant, theta * sqrt(n_study), 1, lower.tail = FALSE)
return(expect)
}
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
expected_pub_prob
n_studies
theta
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(-2, alph, p, n_study))
expected_pub_prob
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(2, alph, p, n_study))
expected_pub_prob
calculate_pub_prob(clt_mix, 0.1)
calculate_pub_prob(clt_mix, 0.1)/expected_pub_prob
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(0.4, alph, p, n_study))
calculate_pub_prob(clt_mix, 0.1)/expected_pub_prob
clt_mix$Tn
clt_mix$mu_hat
clt_mix$mu1_hat
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(0.1, alph, p, n_study))
calculate_pub_prob(clt_mix, 0.1)/expected_pub_prob
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
calculate_pub_prob(clt_mix, 0.1)/expected_pub_prob*likelihood
plot(clt_mix$Tn,  calculate_pub_prob(clt_mix, 0.1)/expected_pub_prob*likelihood)
plot(density(clt_mix$Tn))
lines(clt_mix$Tn,  calculate_pub_prob(clt_mix, 0.1)/expected_pub_prob*likelihood)
points(clt_mix$Tn,  calculate_pub_prob(clt_mix, 0.1)/expected_pub_prob*likelihood)
plot(density(clt_mix$Tn))
points(clt_mix$Tn,  calculate_pub_prob(clt_mix, 0.1)/expected_pub_prob*likelihood)
theta
T_corr
plot(density(clt))
plot(density(clt$Tn))
mean(clt$Tn)
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
#expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#print(exp_pub_prob(theta, alph, p))
lik <- likelihood
return(lik)
}
# check beahviour of significance given increasing n
x_mean <- sapply(seq(1,100), function(i) rnorm(1e5,0.2,1/sqrt(i))*sqrt(i)/1)
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr*2
mean(clt_mix$Tn)
T_corr
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr
mean(clt$Tn)
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr
# expected publication probability
# theta = mu/sgm
exp_pub_prob <- function(theta, alph, p, n_study) {
quant <- qnorm(alph, 0, 1, lower.tail = FALSE)
expect <- p * pnorm(quant / sqrt(n_study), theta, 1 / sqrt(n_study)) +
1 * pnorm(quant / sqrt(n_study), theta, 1 / sqrt(n_study), lower.tail = FALSE)
return(expect)
}
# expected publication probability
# theta = mu/sgm
exp_pub_prob <- function(theta, alph, p, n_study) {
quant <- qnorm(alph, 0, 1, lower.tail = FALSE)
expect <- p * pnorm(quant / sqrt(n_study), theta, 1 / sqrt(n_study)) +
1 * pnorm(quant / sqrt(n_study), theta, 1 / sqrt(n_study), lower.tail = FALSE)
return(expect)
}
# likelihood function
likeli <- function(z, theta, n_study) {
lik <- dnorm(z / sqrt(n_study), mean = theta, 1 / sqrt(n_study)) # same as: dnorm(z-theta,0,1)
return(lik)
}
# expected publication probability
# theta = mu/sgm
exp_pub_prob <- function(theta, alph, p, n_study) {
quant <- qnorm(alph, 0, 1, lower.tail = FALSE)
expect <- p * pnorm(quant / sqrt(n_study), theta, 1 / sqrt(n_study)) +
1 * pnorm(quant / sqrt(n_study), theta, 1 / sqrt(n_study), lower.tail = FALSE)
return(expect)
}
# likelihood function
likeli <- function(z, theta, n_study) {
lik <- dnorm(z / sqrt(n_study), mean = theta, 1 / sqrt(n_study)) # same as: dnorm(z-theta,0,1)
return(lik)
}
# likelihood function
likeli <- function(z, theta, n_study) {
lik <- dnorm(z / sqrt(n_study), mean = theta, 1 / sqrt(n_study)) # same as: dnorm(z-theta,0,1)
return(lik)
}
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn # / sqrt(dat$n_study)
n_studies <- dat$n_study
#sgm <- 1/ sqrt(dat$n_study)
#theta_0 <- mean(dat$Tn)
# checking whether all alpha levels and all transformations are the same
# is done by "calculate_pub_prob"
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likeli(z, theta)
#lik <- likeli(z, theta)
likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies, function(n_study) exp_pub_prob(theta, alph, p, n_study))
#expected_pub_prob <- exp_pub_prob2(theta, alph, p)
#print(expected_pub_prob)
#likelihood <- sapply(1:length(z), function(i) likeli(z[i], theta, sgm[i]))
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#idea: EM algorithm for this value
#lik <- calculate_pub_prob(dat, p) / exp_pub_prob(theta, alph, p) * likelihood
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
#lik <- calculate_pub_prob(dat, p) * likelihood
#print(exp_pub_prob(theta, alph, p))
#lik <- likelihood
return(lik)
}
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
T_corr
aggregate_mean(clt_mix)
pnorm(1-2*3,0,1)
pnorm(1-1*3,0,1)
pnorm(1/3-1,0,1/3)
thetas <- seq(-3, 3, by = 0.01) # theta = mu / sgm_th
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = 1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
mu_corr <- T_corr*clt_mix$sgm_th[1]
# transform Z scores into estimates of mu
z_to_mu <- function(z, n, sgm_X) {
mu_hat <- z * sgm_X / sqrt(n)
return(mu_hat)
}
mu_corr
T_corr
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p = .1)))
plot(thetas, likelihoods, type = "l")
T_corr <- thetas[which(max(likelihoods) == likelihoods)]
mu_corr <- T_corr*clt_mix$sgm_th[1]
mu_corr
trunc_mle <- function(dat, thetas, p) {
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p)))
plot(thetas, likelihoods, type = "l")
T_corr_mle <- thetas[which(max(likelihoods) == likelihoods)]
mu_corr_mle <- T_corr_mle * dat$sgm_th[1]
return(mu_corr_mle)
}
trunc_mle <- function(dat, thetas, p) {
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p)))
plot(thetas, likelihoods, type = "l")
T_corr_mle <- thetas[which(max(likelihoods) == likelihoods)]
mu_corr_mle <- T_corr_mle * dat$sgm_th[1]
return(mu_corr_mle)
}
mu_corr <- trunc_mle(clt_mix, thetas, p = 0.1)
mu_corr
thetas <- seq(-2, 2, by = 0.001) # theta = mu / sgm_th
mu_corr <- trunc_mle(clt_mix, thetas, p = 0.1)
mu_corr
ps <- seq(0, 1, by = 0.01)
mu_corr <- sapply(ps, function(p) trunc_mle(clt_mix, thetas, p))
trunc_mle <- function(dat, thetas, p) {
likelihoods <- sapply(thetas, function(theta) prod(trunc_likeli(clt_mix, theta, p)))
#plot(thetas, likelihoods, type = "l")
T_corr_mle <- thetas[which(max(likelihoods) == likelihoods)]
mu_corr_mle <- T_corr_mle * dat$sgm_th[1]
return(mu_corr_mle)
}
thetas <- seq(-2, 2, by = 0.001) # theta = mu / sgm_th
mu_corr <- trunc_mle(clt_mix, thetas, p = 0.1)
mu_corr
ps <- seq(0, 1, by = 0.01)
mu_corr <- sapply(ps, function(p) trunc_mle(clt_mix, thetas, p))
# for optimisations
require("NMOF")
help(gridSearch)
getwd()
ps <- seq(0, 1, by = 0.01)
thetas
trunc_likeli_helper <- function(theta_p) {
-prod(trunc_likeli(dat, theta_p[1], theta_p[2]))
}
dat <- clt_mix
trunc_likeli_helper <- function(theta_p) {
-prod(trunc_likeli(dat, theta_p[1], theta_p[2]))
}
T_corr_mle <- gridSearch(fun = trun_likeli_helper,
levels = list(thetas, ps),
method = "multicore")
help(gridSearch)
require("reshape2") # https://stackoverflow.com/questions/21563864/ggplot2-overlay-density-plots-r
require("data.table")
# for plotting
require("ggplot2")
require("gridExtra")
# for optimisations
require("NMOF") #gridSearch
# custom functions
source("./functions/helper_functions.R")
T_corr_mle <- gridSearch(fun = trun_likeli_helper,
levels = list(thetas, ps),
method = "multicore")
trunc_likeli_helper(list(1,2))
trunc_likeli_helper <- function(theta_p) {
-prod(trunc_likeli(dat, theta_p[[1]], theta_p[[2]]))
}
trunc_likeli_helper(list(1,2))
trunc_likeli_helper <- function(theta_p) {
-prod(trunc_likeli(dat, theta_p[[1]], theta_p[[2]]))
}
T_corr_mle <- gridSearch(fun = trun_likeli_helper,
levels = list(thetas, ps),
method = "multicore")
list(thetas,ps)
help(gridSearch)
ps <- seq(0, 1, by = 0.01)
trunc_likeli_helper <- function(theta_p, dat) {
-prod(trunc_likeli(dat, theta_p[[1]], theta_p[[2]]))
}
T_corr_mle <- gridSearch(fun = trun_likeli_helper,
levels = list(thetas, ps) dat = dat,
method = "multicore")
T_corr_mle <- gridSearch(fun = trun_likeli_helper,
levels = list(thetas, ps). dat = dat,
method = "multicore")
T_corr_mle <- gridSearch(fun = trun_likeli_helper,
levels = list(thetas, ps), dat = dat,
method = "multicore")
ps <- seq(0.01, 1, by = 0.01)
trunc_likeli_helper <- function(theta_p, dat) {
-prod(trunc_likeli(dat, theta_p[[1]], theta_p[[2]]))
}
T_corr_mle <- gridSearch(fun = trun_likeli_helper,
levels = list(thetas, ps), dat = dat,
method = "multicore")
trunc_likeli_helper(list(0.3,0.1))
trunc_likeli_helper(list(0.3,0.1), clt_mix)
sapply(ps, function(p) trunc_likeli_helper(list(0.2,p), clt_mix))
ps <- seq(0, 1, by = 0.01)
sapply(ps, function(p) trunc_likeli_helper(list(0.2,p), clt_mix))
T_corr_mle <- gridSearch(fun = trun_likeli_helper,
levels = list(thetas, ps), dat = dat,
method = "multicore")
T_corr_mle
trunc_mle$levels
T_corr_mle$levels
T_corr_mle$values
T_corr_mle <- gridSearch(fun = trunc_likeli_helper,
levels = list(thetas, ps), dat = dat,
method = "multicore")
T_corr_mle$minfun
T_corr_mle$minlevels
trunc_likeli()
trunc_likeli
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn
n_studies <- dat$n_study
likelihood <- sapply(1:length(z),
function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies,
function(n_study) exp_pub_prob(theta, alph, p, n_study))
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
return(lik)
}
thetas <- seq(-2, 2, by = 0.001) # theta = mu / sgm_th
mu_corr <- trunc_mle(clt_mix, thetas, p = 0.1)
likelihoods <- sapply(thetas,
function(theta) prod(trunc_likeli(dat, theta, p)))
#plot(thetas, likelihoods, type = "l")
T_corr_mle <- thetas[which(max(likelihoods) == likelihoods)]
mu_corr_mle <- T_corr_mle * dat$sgm_th[1]
mu_corr_mle
# likelihood function
likeli <- function(z, theta, n_study) {
lik <- dnorm(z / sqrt(n_study), mean = theta, 1 / sqrt(n_study))
return(lik)
}
# calculate truncated likelihood of theta given the data
trunc_likeli <- function(dat, theta, p) {
alph <- dat$alpha[1]
z <- dat$Tn
n_studies <- dat$n_study
likelihood <- sapply(1:length(z),
function(i) likeli(z[i], theta, n_studies[i]))
expected_pub_prob <- sapply(n_studies,
function(n_study) exp_pub_prob(theta, alph, p, n_study))
lik <- calculate_pub_prob(dat, p) / expected_pub_prob * likelihood
return(lik)
}
# expected publication probability
# theta = mu/sgm
exp_pub_prob <- function(theta, alph, p, n_study) {
quant <- qnorm(alph, 0, 1, lower.tail = FALSE)
expect <- p * pnorm(quant / sqrt(n_study), theta, 1 / sqrt(n_study)) +
1 * (1 - pnorm(quant / sqrt(n_study), theta, 1 / sqrt(n_study)))
return(expect)
}
clt_mix
p
thetas
likelihoods <- sapply(thetas,
function(theta) prod(trunc_likeli(dat, theta, p)))
#plot(thetas, likelihoods, type = "l")
T_corr_mle <- thetas[which(max(likelihoods) == likelihoods)]
mu_corr_mle <- T_corr_mle * dat$sgm_th[1]
mu_corr_mle
ps <- seq(0, 1, by = 0.01)
trunc_likeli_helper <- function(theta_p, dat) {
-prod(trunc_likeli(dat, theta_p[[1]], theta_p[[2]]))
}
T_corr_mle <- gridSearch(fun = trunc_likeli_helper,
levels = list(thetas, ps), dat = dat,
method = "multicore")
T_corr_mle$minlevels
trunc_mle <- function(dat, thetas, p) {
if (missing(p)){
ps <- seq(0, 1, by = 0.01)
trunc_likeli_helper <- function(theta_p, dat) {
-prod(trunc_likeli(dat, theta_p[[1]], theta_p[[2]]))
}
T_corr_mle <- gridSearch(fun = trunc_likeli_helper,
levels = list(thetas, ps), dat = dat,
method = "multicore")
return(T_corr_mle$minlevels)
} else {
likelihoods <- sapply(thetas,
function(theta) prod(trunc_likeli(dat, theta, p)))
#plot(thetas, likelihoods, type = "l")
T_corr_mle <- thetas[which(max(likelihoods) == likelihoods)]
mu_corr_mle <- T_corr_mle * dat$sgm_th[1]
return(mu_corr_mle)
}
}
minlevels
T_corr_mle$minlevels
# custom functions
source("./functions/helper_functions.R")
# calculate mle with known p
thetas <- seq(-2, 2, by = 0.001) # theta = mu / sgm_th
mu_corr <- trunc_mle(clt_mix, thetas, p = 0.1)
mu_corr
# calculate mle without known p
start.time <- Sys.time()
min_levels <- trunc_mle(clt_mix, thetas)
print(Sys.time() - start.time)
mu_corr <- min_levels[1]
p_mle <- min_levels[2]
p_mle
mu_corr
mu_mle_corr <- min_levels[1]
mu_mle_corr
p_mle <- min_levels[2]
p_mle
mu_mle_corr <- min_levels[[1]]
mu_mle_corr
p_mle <- min_levels[[2]]
p_mle
# calculate mle with known p
thetas <- seq(-2, 2, by = 0.1) # theta = mu / sgm_th
ps <- seq(0, 1, by = 0.1)
# calculate mle without known p
ps <- seq(0, 1, by = 0.1)
start.time <- Sys.time()
min_levels <- trunc_mle(clt_mix, thetas)
print(Sys.time() - start.time)
mu_mle_corr <- min_levels[[1]]
mu_mle_corr
p_mle <- min_levels[[2]]
p_mle
min_levels
# calculate maximum likelihood estimator for truncated likelihood function;
# if publication probability for non-significant studies ("p") is not given,
# a grid search is performed for all possible thetas and p in [0, 1]
trunc_mle <- function(dat, thetas, p) {
if (length(unique(dat$alpha)) > 1 | length(unique(dat$id)) > 1) {
stop("Only test results evaluated at the same alpha threshold
and based on the same evidence metric are permitted.")
} else {
alph <- dat$alpha[1]
}
if (missing(p)){
ps <- seq(0, 1, by = 0.01)
trunc_likeli_helper <- function(theta_p, dat) {
-prod(trunc_likeli(dat, theta_p[[1]], theta_p[[2]]))
}
T_corr_mle <- gridSearch(fun = trunc_likeli_helper,
levels = list(thetas, ps), dat = dat,
method = "multicore")
mu_corr_mle <- T_corr_mle$minlevels[1] * dat$sgm_th[1]
p_mle <- T_corr_mle$minlevels[2]
return(c(mu_corr_mle, p_mle))
} else {
likelihoods <- sapply(thetas,
function(theta) prod(trunc_likeli(dat, theta, p)))
#plot(thetas, likelihoods, type = "l")
T_corr_mle <- thetas[which(max(likelihoods) == likelihoods)]
mu_corr_mle <- T_corr_mle * dat$sgm_th[1]
return(mu_corr_mle)
}
}
# calculate mle without known p
ps <- seq(0, 1, by = 0.1)
start.time <- Sys.time()
min_levels <- trunc_mle(clt_mix, thetas)
print(Sys.time() - start.time)
min_levels
# calculate mle with known p
theta0 <- mean(clt_mix$Tn)/clt_mix$sgm_th[1]
theta0
# calculate mle with known p
theta_0 <- mean(clt_mix$Tn)/clt_mix$sgm_th[1]
thetas <- seq(theta_0-2, theta_0, by = 0.001) # theta = mu / sgm_th
mu_mle_corr <- trunc_mle(clt_mix, thetas, p = 0.1)
mu_mle_corr
# calculate mle without known p
ps <- seq(0, 1, by = 0.01)
start.time <- Sys.time()
min_levels <- trunc_mle(clt_mix, thetas)
print(Sys.time() - start.time)
mu_mle_corr <- min_levels[1]
mu_mle_corr
p_mle <- min_levels[2]
p_mle
reise <- 40
reise <- 100
unterkunft <- (450+300)/2
reise+unterkunft
594+200
470*1.16
